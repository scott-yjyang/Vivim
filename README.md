# Vivim
Vivim: a Video Vision Mamba for Medical Video Object Segmentation 

[[arXiv](https://arxiv.org/abs/2401.14168)]

Here is a project for Mamba in videosğŸ˜„. 
Please stay tuned for our work.

## News
- 24-02-08. â—â—Important update on Method and Experiments. Please refer to [[arXiv](https://arxiv.org/abs/2401.14168)] for details.
- 24-01-26. This project is still quickly updating ğŸŒ. Check TODO list to see what will be released next.
- 24-01-25. The paper has been released on arXiv.



## A Quick Overview 

<img width="600" height="400" src="https://github.com/scott-yjyang/Vivim/blob/main/assets/framework.png">



### TODO LIST

- [ ] Release Model
- [ ] Release training scripts
- [ ] Release evaluation
- [ ] Experiments on other video object segmentation datasets.
- [ ] configuration



## Thanks

Code is based on [ge-xing/SegMamba](https://github.com/ge-xing/SegMamba), [hustvl/Vim](https://github.com/hustvl/Vim), [bowang-lab/U-Mamba](https://github.com/bowang-lab/U-Mamba).

## Cite
If you find it useful, please cite
~~~
@article{yang2024vivim,
  title={Vivim: a Video Vision Mamba for Medical Video Object Segmentation},
  author={Yang, Yijun and Xing, Zhaohu and Zhu, Lei},
  journal={arXiv preprint arXiv:2401.14168},
  year={2024}
}
~~~
